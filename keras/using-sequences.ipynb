{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [https://machinelearningmastery.com/reproducible-results-neural-networks-keras/](https://machinelearningmastery.com/reproducible-results-neural-networks-keras/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame, concat\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),\n",
       " array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create sequence\n",
    "length = 11\n",
    "sequence = [i/ 10.0 for i in range(length)]\n",
    "# create X/y pairs\n",
    "df = DataFrame(sequence)\n",
    "df = concat([df.shift(1), df], axis=1)\n",
    "df.dropna(inplace=True)\n",
    "# convert to MLPfriendly format\n",
    "values = df.values\n",
    "X, y = values[:,0], values[:,1]\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=1))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# fit network\n",
    "#model.fit(X, y, epochs=1000, batch_size=len(X), verbose=0)\n",
    "# forecast\n",
    "#yhat = model.predict(X, verbose=0)\n",
    "#print(mean_squared_error(y, yhat[:,0]))\n",
    "#yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `keras.utils.Sequence`\n",
    "\n",
    "From [https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly](https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'validation': ['1.0', '1.1', '1.2', '1.3', '1.4', '1.5'], 'train': ['0.0', '0.1', '0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8', '0.9']}\n"
     ]
    }
   ],
   "source": [
    "partition = {}\n",
    "partition['validation'] = [f'{(l/10.0):0.2}' for l in range(length - 1, length + 5)]\n",
    "partition['train'] = [f'{l:0.2}' for l in X]\n",
    "print(partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1.0': 1.1, '1.1': 1.2000000000000002, '1.2': 1.3, '1.3': 1.4000000000000001, '1.4': 1.5, '1.5': 1.6, '0.0': 0.1, '0.1': 0.2, '0.2': 0.30000000000000004, '0.3': 0.4, '0.4': 0.5, '0.5': 0.6, '0.6': 0.7, '0.7': 0.7999999999999999, '0.8': 0.9, '0.9': 1.0}\n"
     ]
    }
   ],
   "source": [
    "labels = { l:float(l)+0.1 for l in partition['validation'] + partition['train']}\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "\n",
    "    def __init__(self, data_ids, labels, shuffle=True):\n",
    "        \"\"\"Initialization\"\"\"\n",
    "        self.labels = labels\n",
    "        self.batch_size = 5\n",
    "        self.data_ids = data_ids\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Updates indexes after each epoch\"\"\"\n",
    "        self.indexes = np.arange(len(self.data_ids))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, temporary_list_id):\n",
    "        \"\"\"Generates data containing batch_size sample\"\"\"\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size))\n",
    "        y = np.empty((self.batch_size))\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(temporary_list_id):\n",
    "            # Store sample\n",
    "            X[i,] = self.__get_datapoint(ID)\n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def __get_datapoint(self, identifier):\n",
    "        \"\"\"Perform complicated logic here\"\"\"\n",
    "        return float(identifier)\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        number_of_batches = int(np.floor(len(self.data_ids) / self.batch_size))\n",
    "        return number_of_batches\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        temp_ids = [self.data_ids[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(temp_ids)\n",
    "        return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGenerator(partition['train'], labels)\n",
    "validation_generator = DataGenerator(partition['validation'], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.960299093427971e-16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.1       ],\n",
       "       [0.19999999],\n",
       "       [0.3       ],\n",
       "       [0.40000004],\n",
       "       [0.5       ],\n",
       "       [0.59999996],\n",
       "       [0.70000005],\n",
       "       [0.79999995],\n",
       "       [0.9       ],\n",
       "       [1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=training_generator,\n",
    "                    validation_data=validation_generator, epochs=1000, verbose=0)\n",
    "\n",
    "yhat = model.predict(X, verbose=0)\n",
    "print(mean_squared_error(y, yhat[:,0]))\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
